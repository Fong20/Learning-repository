# 07. Software Testing
- Testing is intended to show that a program does what it is intended to do and to discover program defects before it is put into use.
- When testing a software, we execute a program using artificial data. 

## Software testing goals
- To demonstrate to the developer and the customer that the software meets its requirements.
- For custom software, this means that there should be at least one test for every requirement in the requirements document. For generic software products, it means that there should be tests for all of the system features, plus combinations of these features, that will be incorporated in the product release.
- To discover situations in which the behavior of the software is incorrect, undesirable or does not conform to its specification.
  
## Validation and defect testing
There are two primary goals in mind when testing, which is to verify (defect test) and validate

### Validation testing
- The first goal leads to validation testing
- To demonstrate to the developer and the system customer that the software meets its requirements
- A successful test shows that the system operates as intended.

### Defect testing
- The second goal leads to defect testing
- Defect testing is concerned with rooting out undesirable system behavior such as system crashes, unwanted interactions with other systems, incorrect computations and data corruption.
- It basically discovers faults or defects in the software where its behaviour is incorrect or not in conformance with its specification
- A successful test is a test that makes the system perform incorrectly and so exposes a defect in the system.

## Software testing process

![image](https://github.com/user-attachments/assets/58748c8a-9250-43a4-a369-cf01557dc003)

## Stages of testing
1. Development testing, where the system is tested during development to discover bugs and defects.
2. Release testing, where a separate testing team test a complete version of the system before it is released to users.
3. User testing, where users or potential users of a system test the system in their own environment.

### Development testing 
Development testing includes all testing activities that are carried out by the team developing the system. 

#### Type of development testing
1. **Unit testing (object testing)**
- individual program units or object classes are tested. Unit testing should focus on testing the **functionality of objects or methods.**
- It is a defect testing process

   **Object class testing**
   
   The complete test coverage of a class involves:
   - Testing all operations associated with an object
   - Setting and interrogating all object attributes
   - Exercising the object in all possible states.

Inheritance makes it more difficult to design object class tests as the information to be tested is not localised.

2. **Component testing**
- Software components are often composite components that are made up of several interacting objects. 
- The functionality of these objects are accessed through the defined component interface. 
- Component testing should focus on **testing component interfaces.** where it shows that the component interface behaves according to its specification, aassuming that unit tests on the individual objects within the component have been completed. 

   **Interface testing**
   - Objectives are to detect faults due to interface errors or invalid assumptions about interfaces.
   
   **Interface types**
   1. Parameter interfaces
   Data passed from one method or procedure to another.
   
   2. Shared memory interfaces
   Block of memory is shared between procedures or functions.
   
   3. Procedural interfaces
   Sub-system encapsulates a set of procedures to be called by other sub-systems.
   
   4. Message passing interfaces
   Sub-systems request services from other sub-systems
   
   **Interface errors**
   1. Interface misuse
   - A calling component calls another component and makes an error in its use of its interface e.g. parameters in the wrong order.
   
   2. Interface misunderstanding
   - A calling component embeds assumptions about the behaviour of the called component which are incorrect.
   
   3. Timing errors
   - The called and the calling component operate at different speeds and out-of-date information is accessed.
   
   **Interface testing guidelines**
   - Design tests so that parameters to a called procedure are at the extreme ends of their ranges.
   - Always test pointer parameters with null pointers.
   - Design tests which cause the component to fail.
   - Use stress testing in message passing systems.
   - In shared memory systems, vary the order in which components are activated.

3. **System testing**
- System testing during development involves integrating components to create a version of the system and then testing the integrated system.
- The focus in system testing is testing the interactions between components.
- System testing checks that components are compatible, interact correctly and transfer the right data at the right time across their interfaces.
- System testing tests the emergent behaviour of a system.
- During system testing, reusable components that have been separately developed and off-the-shelf systems may be integrated with newly developed components. The complete system is then tested.
- Components developed by different team members or sub-teams may be integrated at this stage. System testing is a collective rather than an individual process. 

### Release testing
- Release testing is the process of testing a particular release of a system that is intended for use outside of the development team.
- The primary goal of the release testing process is to convince the supplier of the system that it is good enough for use.
- Release testing, therefore, has to show that the system delivers its specified functionality, performance and dependability, and that it does not fail during normal use.
- Release testing is usually a black-box testing process where tests are only derived from the system specification.

#### Release testing VS System testing
- Release testing is a form of system testing.

**Differences between release testing and system testing is:**
- A separate team that has **not been involved in the system development, should be responsible for release testing.**
- System testing by the development team should focus on discovering bugs in the system (defect testing). The **objective of release testing is to check that the system meets its requirements and is good enough for external use (validation testing).**

#### Requirements based testing
Requirements-based testing involves examining each requirement and developing a test or tests for it.

#### Performance testing
- Part of release testing may involve **testing the emergent properties of a system, such as performance and reliability.**
- Tests should reflect the profile of use of the system.
- Performance tests usually involve planning a series of tests where the load is steadily increased until the system performance becomes unacceptable.
- Stress testing is a form of performance testing where the system is deliberately overloaded to test its failure behaviour.

#### User testing
- User or customer testing is a stage in the testing process in which users or customers provide input and advice on system testing.
- User testing is essential, even when comprehensive system and release testing have been carried out.
- The reason for this is that influences from the user’s working environment have a major effect on the reliability, performance, usability and robustness of a system. These cannot be replicated in a testing environment.

**Types of user testing**
1. Alpha testing
- Users of the software work with the development team to test the software at the developer’s site.

2. Beta testing
- A release of the software is made available to users to allow them to experiment and to raise problems that they discover with the system developers.

3. Acceptance testing
- Customers test a system to decide whether or not it is ready to be accepted from the system developers and deployed in the customer environment. Primarily for custom systems.

**Acceptance testing process**
1. Define acceptance criteria
2. Plan acceptance testing
3. Derive acceptance tests
4. Run acceptance tests
5. Negotiate test results
6. Reject/accept system
   
![image](https://github.com/user-attachments/assets/911abb56-21e0-4862-8e2a-b66c1282eafa)

## Testing strategies
1. Partition testing, where you identify groups of inputs that have common characteristics and should be processed in the same way. 
- You should choose tests from within each of these groups
  
2. Guideline-based testing, where you use testing guidelines to choose test cases. 
- These guidelines reflect previous experience of the kinds of errors that programmers often make when developing components.

**General testing guidelines:**
- Choose inputs that force the system to generate all error messages
- Design inputs that cause input buffers to overflow
- Repeat the same input or series of inputs numerous times
- Force invalid outputs to be generated
- Force computation results to be too large or too small.


